import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    const { photoAvant, photoApres, nomMateriel } = await request.json();

    if (!photoApres) {
      return NextResponse.json({ error: 'Photo APR√àS requise' }, { status: 400 });
    }

    // V√©rifier que les photos ne sont pas en base64 (non support√© par OpenAI sans transformation)
    if (photoApres.startsWith('data:')) {
      console.warn('‚ö†Ô∏è Photo en base64 d√©tect√©e, OpenAI n√©cessite une URL publique');
      return NextResponse.json({ 
        error: 'Format non support√©', 
        message: 'L\'analyse IA n√©cessite que les photos soient upload√©es sur Supabase Storage. Les photos en base64 ne peuvent pas √™tre analys√©es.',
        recommendation: 'Configurez Supabase Storage pour activer l\'analyse IA automatique.'
      }, { status: 400 });
    }

    // V√©rifier le format de fichier (OpenAI ne supporte pas HEIC)
    if (photoApres.includes('.HEIC') || photoApres.includes('.heic') || photoApres.includes('.HEIF') || photoApres.includes('.heif')) {
      console.warn('‚ö†Ô∏è Format HEIC d√©tect√© (iPhone), non support√© par OpenAI Vision');
      return NextResponse.json({ 
        error: 'Format HEIC non support√©', 
        message: 'Les photos au format HEIC (iPhone) ne peuvent pas √™tre analys√©es par l\'IA. OpenAI Vision supporte uniquement : PNG, JPEG, GIF, WEBP.',
        recommendation: 'Sur iPhone : R√©glages ‚Üí Appareil photo ‚Üí Formats ‚Üí Choisir "Plus compatible" pour prendre des photos en JPEG au lieu de HEIC.'
      }, { status: 400 });
    }

    if (photoAvant && photoAvant.startsWith('data:')) {
      console.warn('‚ö†Ô∏è Photo AVANT en base64, analyse uniquement de la photo APR√àS');
      // On continue sans photo AVANT si elle est en base64
    }

    // Si pas de photo AVANT, analyser seulement l'√©tat actuel
    if (!photoAvant) {
      const response = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          {
            role: "user",
            content: [
              {
                type: "text",
                text: `Tu es un expert en inspection de mat√©riel audiovisuel professionnel. Analyse cette photo de ${nomMateriel} et documente son √©tat actuel de mani√®re exhaustive.

Identifie:
- √âtat g√©n√©ral (Excellent/Bon/Traces l√©g√®res/Rayures/Chocs/D√©gradation/Non-fonctionnel)
- Tous les d√©fauts visibles (rayures, chocs, salissures, traces de liquide, d√©formations)
- Localisation pr√©cise de chaque d√©faut
- Gravit√© de chaque d√©faut

R√©ponds au format JSON:
{
  "etatGeneral": "Bon",
  "defauts": [
    {
      "type": "rayure",
      "localisation": "panneau lat√©ral gauche",
      "gravite": "l√©g√®re",
      "description": "Rayure de 3cm peu profonde"
    }
  ],
  "commentaire": "Description g√©n√©rale de l'√©tat",
  "recommandation": "OK" | "ATTENTION" | "FACTURATION"
}`
              },
              {
                type: "image_url",
                image_url: { url: photoApres }
              }
            ]
          }
        ],
        max_tokens: 1000,
        temperature: 0.2,
      });

      const content = response.choices[0].message.content;
      if (!content) {
        throw new Error('Pas de r√©ponse de GPT-4');
      }

      // Parser la r√©ponse JSON
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      const analysis = jsonMatch ? JSON.parse(jsonMatch[0]) : null;

      return NextResponse.json({
        analysis,
        timestamp: new Date().toISOString(),
        model: 'gpt-4o'
      });
    }

    // Analyse comparative AVANT vs APR√àS
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: `Tu es un expert en inspection de mat√©riel audiovisuel professionnel. 

MISSION CRITIQUE: Compare ces 2 photos du M√äME √©quipement (${nomMateriel}):
- Photo 1 = √âtat √† la LIVRAISON (AVANT)
- Photo 2 = √âtat √† la REPRISE (APR√àS)

Identifie TOUS les changements, m√™me minimes:
- Rayures (nouvelles, absentes sur photo AVANT)
- Chocs, bosses, d√©formations
- Salissures, traces de liquide, taches
- √âl√©ments manquants, cass√©s
- Usure visible
- Toute diff√©rence visible

Pour CHAQUE diff√©rence d√©tect√©e, indique:
- Type de dommage
- Localisation PR√âCISE
- Gravit√© (l√©g√®re/moyenne/grave)
- Comparaison AVANT/APR√àS

IMPORTANT:
- Si AUCUNE diff√©rence: le dire clairement
- Ne mentionne PAS les diff√©rences d'angle/√©clairage
- Focus uniquement sur les DOMMAGES PHYSIQUES

R√©ponds au format JSON strict:
{
  "etatGeneral": "Bon" | "Usure normale" | "D√©gradation visible" | "Mat√©riel endommag√©" | "Casse",
  "changementsDetectes": true | false,
  "nouveauxDommages": [
    {
      "type": "rayure" | "choc" | "salissure" | "liquide" | "casse" | "manquant",
      "localisation": "description pr√©cise",
      "gravite": "l√©g√®re" | "moyenne" | "grave",
      "description": "description d√©taill√©e",
      "visible_avant": false
    }
  ],
  "commentaireComparatif": "R√©sum√© de la comparaison",
  "recommandation": "OK" | "USURE_NORMALE" | "FACTURATION_LEGERE" | "FACTURATION_IMPORTANTE",
  "montantEstime": 0
}`
            },
            {
              type: "text",
              text: "Photo AVANT (livraison):"
            },
            {
              type: "image_url",
              image_url: { url: photoAvant }
            },
            {
              type: "text",
              text: "Photo APR√àS (reprise):"
            },
            {
              type: "image_url",
              image_url: { url: photoApres }
            }
          ]
        }
      ],
      max_tokens: 1500,
      temperature: 0.1, // Tr√®s faible pour objectivit√© maximale
    });

    const content = response.choices[0].message.content;
    if (!content) {
      throw new Error('Pas de r√©ponse de GPT-4');
    }

    // Parser la r√©ponse JSON
    const jsonMatch = content.match(/\{[\s\S]*\}/);
    const analysis = jsonMatch ? JSON.parse(jsonMatch[0]) : null;

    return NextResponse.json({
      analysis,
      timestamp: new Date().toISOString(),
      model: 'gpt-4o',
      photoAvantUrl: photoAvant,
      photoApresUrl: photoApres
    });

  } catch (error: any) {
    console.error('Erreur analyse GPT-4:', error);
    
    // D√©tecter erreur sp√©cifique OpenAI
    if (error?.code === 'invalid_image_url') {
      console.error('‚ùå OpenAI ne peut pas t√©l√©charger l\'image depuis Supabase');
      console.error('üí° SOLUTION: Rendez le bucket "materiel-photos" PUBLIC dans Supabase');
      console.error('   1. Dashboard Supabase ‚Üí Storage ‚Üí materiel-photos');
      console.error('   2. ... (3 points) ‚Üí Edit bucket ‚Üí Cocher "Public bucket"');
      console.error('   3. Ou ex√©cutez: UPDATE storage.buckets SET public = true WHERE id = \'materiel-photos\'');
      
      return NextResponse.json(
        { 
          error: 'Bucket Supabase non accessible',
          message: 'OpenAI ne peut pas t√©l√©charger l\'image. Le bucket "materiel-photos" doit √™tre configur√© comme PUBLIC dans Supabase.',
          recommendation: 'Voir le fichier SUPABASE_BUCKET_PUBLIC.md pour les instructions compl√®tes.',
          code: 'SUPABASE_BUCKET_NOT_PUBLIC'
        },
        { status: 400 }
      );
    }
    
    if (error?.code === 'invalid_image_format') {
      return NextResponse.json(
        { 
          error: 'Format d\'image non support√©',
          message: error.message || 'Format non reconnu par OpenAI Vision API',
          recommendation: 'Utilisez uniquement JPEG, PNG, GIF ou WEBP. √âvitez HEIC (iPhone).',
          code: 'INVALID_FORMAT'
        },
        { status: 400 }
      );
    }
    
    return NextResponse.json(
      { 
        error: 'Erreur lors de l\'analyse', 
        details: error instanceof Error ? error.message : 'Erreur inconnue',
        code: error?.code || 'UNKNOWN_ERROR'
      },
      { status: 500 }
    );
  }
}

